# UnitTest Auto-Fix: AI 驱动的单元测试修复工具

`unittest_auto_fix.py` 是一个强大而智能的命令行工具，旨在利用大型语言模型（LLM）和动态代码分析技术，实现 Python 单元测试的自动化分析与修复。

## 简介

在软件开发周期中，修复失败的单元测试是一项耗时且重复性高的工作。本工具通过以下方式将开发者从繁琐的调试中解放出来：

- **自动化**: 自动执行测试、定位失败、分析根本原因、生成修复补丁并验证修复效果。
- **智能化**: 结合了强大的动态代码追踪能力，能捕捉测试失败时的完整执行上下文（调用栈、变量值），为 AI 提供远超静态代码分析的信息。
- **高效率**: 提供多种工作流，包括并行分析和全自动修复，能极大地缩短回归测试和 bug 修复周期。
- **灵活性**: 支持从完全交互式的手动确认到“无人驾驶”的全自动模式，适应不同的开发需求。

## 工作原理

工具的核心工作流可以分为以下几个关键步骤：

1.  **测试执行与追踪 (Test Execution & Tracing)**
    - 工具首先会执行指定的单元测试。
    - 在执行过程中，一个内置的动态追踪器 (`debugger.tracer`) 会被激活。它会记录下详细的运行时信息，包括函数调用、返回、异常抛出以及关键变量在执行过程中的值，并将这些信息保存为日志。

2.  **错误分析 (Error Analysis)**
    - 当一个测试失败或出错时，工具会解析测试报告，提取出错误的类型、信息以及关键的堆栈跟踪（traceback）。

3.  **智能上下文构建 (Smart Context Building)**
    - 这是工具的“秘密武器”。为了让 LLM 在有限的上下文窗口内理解问题，工具会：
        - 根据错误发生的文件和行号，从追踪日志中重建导致失败的**精确调用链**。
        - **优先选择**位于异常调用链上的函数代码作为核心上下文。
        - 如果上下文预算还有剩余，它会智能地选择在本次测试执行中被调用过的其他相关函数（优先选择代码量小的函数），以提供更全面的背景信息。
    - 这种方法远比简单地将整个文件丢给 LLM 要高效和精准。

4.  **AI 分析与修复 (AI Analysis & Patching)**
    - 工具将整合后的信息——包括错误报告、追踪日志、智能上下文（相关代码片段）以及用户的特定指令——构建成一个结构化的提示（Prompt）。
    - 该提示被发送给指定的大型语言模型（例如 GPT-4, DeepSeek Coder V2等）。
    - LLM 根据这些信息进行深度分析，并生成一份可以直接应用的 `diff` 格式的代码补丁。

5.  **应用补丁 (Patch Application)**
    - 工具解析 LLM 返回的补丁，并将其自动应用到项目的源代码文件中。

6.  **循环验证 (Verification Loop)**
    - 代码被修补后，工具会自动重新加载被修改的模块，并再次运行测试。
    - 如果测试通过，流程结束或进入下一个错误的修复。如果测试仍然失败，工具（在自动模式下）会记录一次尝试，并可能在达到重试上限后放弃该错误，以避免无限循环。

## 安装与配置

1.  **环境依赖**:
    请确保已安装所有必要的 Python 包。
    ```bash
    pip install colorama tqdm
    ```

2.  **LLM 配置**:
    工具需要通过 `llm_query` 模块与 LLM 服务进行交互。请确保您已在 `llm_query/config.py` 文件中正确配置了所使用模型的 API Key 和 Base URL。

## 使用方式

工具通过命令行启动，基本格式如下：
```bash
python gpt_workflow/unittest_auto_fix.py [WORKFLOW_MODE] [OPTIONS] [test_patterns...]
```
- `WORKFLOW_MODE`: 指定工具的核心工作模式，如 `--auto-pilot`。这些模式通常是互斥的。
- `OPTIONS`: 对工作模式进行微调的选项，如 `--model`。
- `test_patterns`: 指定要运行的测试用例，支持通配符和特定测试用例的筛选。

## 命令行参数详解

| 参数 (Option) | 缩写 | 说明 |
| :--- | :--- | :--- |
| `test_patterns` | | **[位置参数]** 指定要运行的测试。支持 `unittest` 的原生选择器语法。例如：`tests/test_api.py`, `+test_feature_*`, `TestClass.test_method`。 |
| `--list-tests` | | 列出所有可用的测试用例，但不执行它们。 |
| `--lookup FILE LINE` | | **[调试工具]** 查找并显示指定文件和行号的追踪日志和调用链信息，用于辅助手动调试。 |
| `--user-requirement "..."` | | 向 AI 的提示中添加一段自定义的用户需求或指令。 |
| `--model MODEL_NAME` | | 指定用于**生成修复代码**的 LLM（"Fixer" 模型）。默认为 `deepseek-r1`。 |
| `--analyzer-model MODEL_NAME`| | 指定用于**分析失败原因**的 LLM（"Analyzer" 模型）。如果未提供，则默认使用与 `--model` 相同的模型。 |
| `--report-dir DIR_PATH` | | 在 `--auto-pilot` 模式下，指定保存分析报告的目录。 |
| `--verbosity` | `-v` | 设置测试输出的详细程度 (0=安静, 1=默认, 2=详细)。 |
| **工作流模式 (互斥)** | | |
| (无特定模式) | | 默认进入**标准交互式修复**流程。 |
| `--direct-fix` | | **[交互模式]** 启动一个简化的交互式修复流程，跳过“分析-反馈-修复”的两步过程，直接生成修复方案。 |
| `--auto-pilot` | | **[全自动模式]** 启动“自动驾驶”模式。工具会自动循环执行“测试-分析-修复”流程，直到所有测试通过或达到重试上限。 |
| `--parallel-analysis [N]`| | **[并行交互模式]** 首先并行分析所有失败的测试（可指定 `N` 个工作线程），然后提供一份包含 AI 分析摘要的列表，让用户选择要修复哪一个。 |
| `--parallel-autofix [N]` | | **[并行自动模式]** 首先并行分析所有失败的测试，然后**依次**为每个分析成功的问题自动应用修复补丁，最后重新运行所有测试。 |

---

## 使用教程

### 场景一：交互式修复单个错误

这是最基础和最常用的模式，它让您对修复过程有完全的控制。

1.  **启动测试**
    运行脚本，可以指定一个或多个测试目标。
    ```bash
    python gpt_workflow/unittest_auto_fix.py tests/test_failing_module.py
    ```

2.  **选择错误**
    测试运行后，工具会列出所有失败和错误的测试。如果多于一个，它会提示您选择要修复哪一个。
    ```text
    Please select an issue to fix:
    ==================================================
      1: [FAILURE] in test_user_creation (AssertionError)
         File: /path/to/tests/test_failing_module.py:25
         Msg:  False is not true : User should be active after creation
    ==================================================
    Enter the number of the issue to fix (1-1), or 'q' to quit: 1
    ```

3.  **分析与修复模式选择**
    在交互模式下，您可以选择修复策略：
    ```text
    请选择修复模式：
    1. 解释并修复 (两步, 包含用户反馈)
    2. 直接修复 (一步)
    3. 退出
    请选择 (1/2/3): 1
    ```
    - **解释并修复 (推荐)**: AI 首先会生成一份详细的失败原因分析报告。您可以审查这份报告，然后基于它给出最终的修复指令（例如“同意分析，请修复”或“分析不对，应该关注XXX”）。
    - **直接修复**: AI 会跳过解释步骤，直接生成代码补丁。

4.  **应用补丁并继续**
    AI 生成补丁并应用后，会询问您是否继续修复下一个问题或重新运行测试。

### 场景二：全自动修复所有错误 (Auto-Pilot)

当您有一系列回归测试失败，并希望工具能自动处理时，此模式是最佳选择。

1.  **启动 Auto-Pilot**
    ```bash
    python gpt_workflow/unittest_auto_fix.py --auto-pilot
    ```

2.  **观察进程**
    工具将进入一个全自动循环：
    - 运行所有测试。
    - 如果有失败，选择第一个未达到重试上限的错误。
    - 分析错误、生成报告（并保存到 `--report-dir`）、生成并应用补丁。
    - 重新开始循环，直到所有测试通过。

3.  **查看报告**
    在 `--report-dir` 指定的目录中，您会找到每个修复尝试的详细 Markdown 报告，内容包括：
    - 测试失败信息
    - AI 的根本原因分析
    - 用于生成修复的完整 Prompt

### 场景三：高效处理多个错误 (并行分析 + 交互式修复)

当一次提交导致多个测试失败时，此模式可以节省大量等待 AI 分析的时间。

1.  **启动并行分析**
    您可以指定并行工作的线程数，默认为 CPU 核心数。
    ```bash
    python gpt_workflow/unittest_auto_fix.py --parallel-analysis 4
    ```

2.  **等待分析完成**
    工具会首先运行测试，然后将所有失败的用例提交到一个线程池进行并行分析。您会看到一个进度条。
    ```text
    Analyzing errors: 100%|██████████| 5/5 [00:30<00:00,  6.00s/it]
    ```

3.  **从分析结果中选择**
    分析完成后，工具会展示一个增强版的错误列表，每个条目都附带了 AI 的分析摘要。
    ```text
    Please select an issue to fix based on the AI's analysis:
    ==============================================================
      1: [FAILURE] in test_user_creation (AssertionError)
         File: /path/to/tests/test_users.py:25
         Analysis: 问题在于 `create_user` 函数未正确设置 `is_active` 默认值...
      2: [ERROR] in test_profile_update (TypeError)
         File: /path/to/tests/test_profiles.py:42
         Analysis: `update_profile` 尝试对 NoneType 对象 `profile.settings` 进行了...
    ==============================================================
    ```
    您可以根据这些摘要判断哪个修复更有可能成功，或选择您想优先处理的问题。接下来的步骤与标准交互式修复相同。

### 场景四：全自动并行修复 (`--parallel-autofix`)

此模式结合了并行分析的速度和全自动修复的便利性，是 CI/CD 或需要对一批错误进行快速、无人值守修复时的理想选择。

1.  **启动并行自动修复**
    ```bash
    python gpt_workflow/unittest_auto_fix.py --parallel-autofix 4
    ```

2.  **观察自动化流程**
    工具将完全自动地执行以下步骤，无需用户干预：
    - **运行测试**: 找出所有失败的测试用例。
    - **并行分析**: 使用 4 个工作线程并发分析所有失败。
    - **串行修复**: 分析完成后，工具会**依次（一个接一个地）**为每个分析成功的错误应用修复补丁。**这种串行修复的设计是为了确保鲁棒性，避免多个进程在同一时间修改同一个代码文件而引发冲突。**
    - **循环验证**: 当一个批次的所有补丁都应用后，工具会自动重新运行完整的测试套件，以验证修复效果并开始新的“测试-分析-修复”循环，直到所有问题解决。

### 场景五：辅助手动调试 (Lookup)

如果您只是想理解某段代码的行为，而不是让 AI 修复它，`--lookup` 模式非常有用。

1.  **运行 Lookup**
    ```bash
    python gpt_workflow/unittest_auto_fix.py --lookup /path/to/app/main.py 55
    ```

2.  **查看追踪日志**
    工具会立即输出与 `main.py` 第 55 行相关的最新追踪日志和调用链信息，让您能清晰地看到在测试运行时，该代码行是如何被调用、传入了什么参数、以及后续的执行路径。这对于手动调试非常有价值。

## 总结

`unittest_auto_fix.py` 不仅仅是一个 bug 修复工具，更是一个现代化的开发助手。它通过深度集成动态分析与 LLM 的推理能力，将自动化测试提升到了一个新的水平，能够显著提升开发与维护的效率。